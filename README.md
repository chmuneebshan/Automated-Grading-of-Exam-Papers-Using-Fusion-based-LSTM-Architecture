# ðŸ“š Automated Grading of Exam Papers Using Fusion-Based LSTM Architecture

This repository contains the full implementation of the MSc Data Science final project titled **"Automated Grading of Exam Papers Using Fusion-Based LSTM Architecture"**.  
It includes feature engineering, sentence vectorization, model development (fusion and baseline models), hyperparameter tuning, and evaluation.

---

## ðŸš€ Project Overview

Manual essay grading is time-consuming, subjective, and inconsistent.  
This project proposes a deep learning-based **fusion architecture** combining CNN and BiLSTM to automate grading by learning:
- Vocabulary-level features
- Readability-level features
- Sentence-level semantic vectors
- Chapter-level topic distributions

âœ… Achieved **QWK = 0.981**, **RÂ² = 0.962**, outperforming baseline models and prior studies.

---

## ðŸ“ Repository Structure

```
â”œâ”€â”€ App/
â”‚   â””â”€â”€ main.py                # Main script to run the application
â”‚
â”œâ”€â”€ Code/
â”‚   â”œâ”€â”€ Feature Engineering.ipynb        # Feature extraction from essays
â”‚   â”œâ”€â”€ Modelling.ipynb                   # Fusion model training
â”‚   â””â”€â”€ Baseline LSTM Modeling.ipynb       # Baseline non-fusion LSTM model training
â”‚
â”œâ”€â”€ Data/
â”‚   â”œâ”€â”€ Raw/                     # Raw ASAP dataset (input essays)
â”‚   â”œâ”€â”€ Processed/                # Preprocessed cleaned data
â”‚   â”œâ”€â”€ Features/                 # Vocabulary, readability, and chapter-level features
â”‚   â””â”€â”€ nltk_data/                # Downloaded NLTK resources
â”‚
â”œâ”€â”€ Outputs/
â”‚   â”œâ”€â”€ Model/
â”‚   â”‚   â”œâ”€â”€ word2vec_model.model      # Word2Vec trained model
â”‚   â”‚   â”œâ”€â”€ doc2vec_model.model       # Doc2Vec model
â”‚   â”‚   â”œâ”€â”€ lda_model.model           # LDA topic model
â”‚   â”‚   â”œâ”€â”€ lsi_model.model           # LSI semantic model
â”‚   â”‚   â””â”€â”€ corpus_dictionary.dict    # Gensim dictionary for topic models
â”‚   â””â”€â”€ Baseline/             # Predictions, evaluation plots, etc.
â”‚
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt          # Required Python packages
```

---

## ðŸ”¥ Key Features

- **Feature Engineering:** Length-based, POS-based, punctuation-based, readability indices, semantic embeddings.
- **Fusion Model Architecture:**
  - Vocabulary â†’ CNN
  - Readability â†’ CNN
  - Sentence Vectors â†’ BiLSTM
  - Chapter-Level Topics â†’ BiLSTM
  - Final Dense fusion layers
- **Baseline Non-Fusion Model:** Basic LSTM with vocab inputs for comparison.
- **Hyperparameter Tuning:** RandomSearch using KerasTuner.

---

## ðŸ“Š Results Summary

| Metric | Fusion Model | Baseline LSTM |
|:------:|:------------:|:-------------:|
| MSE    | 2.92          | 10.30         |
| MAE    | 0.93          | 2.47          |
| RÂ²     | 0.962         | 0.868         |
| QWK    | 0.981         | 0.933         |

âœ… Fusion model clearly outperforms the baseline and literature benchmarks.

---

## âš™ï¸ Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/automated-essay-grading.git
   cd automated-essay-grading
   ```

2. Install the requirements:
   ```bash
   pip install -r requirements.txt
   ```

3. Download the **ASAP Automated Essay Scoring** dataset from Kaggle and place it inside `Data/Raw/`.

4. Run the notebooks in `Code/` step-by-step:
   - Feature extraction
   - Sentence vectorization
   - Model training
   - Evaluation

---

## ðŸ§ª Major Libraries Used

- **TensorFlow / Keras**
- **Gensim** (Word2Vec, Doc2Vec, LDA, LSI)
- **Scikit-learn** (Evaluation metrics)
- **TextStat** (Readability scoring)
- **NLTK** (Text preprocessing)

---

## ðŸ’» How to Run

- Run `Feature Engineering.ipynb` to generate features.
- Train models using `Modelling.ipynb` (Fusion model) or `Baseline LSTM Modeling.ipynb`.
- Run `main.py` to start app.

---

> ðŸ“¢ **Note:**  
> This repository showcases that integrating handcrafted features with deep learning representations can build practical, scalable, and reliable automated grading solutions.
